{
"model": "eleldar/language-detection",
"description": "This model is an XLM-RoBERTa transformer model with a classification head on top (i.e. a linear layer on top of the pooled output). For additional information please refer to the xlm-roberta-base model card or to the paper Unsupervised Cross-lingual Representation Learning at Scale by Conneau et al.",
"inputs": [{ "type": "textarea", "id": "inputs", "name": "Text", "placeholder": "Text to detect language from", "default": "Ein jeder kehr’ vor seiner Tür, und rein ist jedes Stadtquartier." }],
"outputType": "table"
}
